{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "from bs4 import BeautifulSoup\n",
    "import requests\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_page(link = '/soccer'):\n",
    "    page_link = 'http://www.betexplorer.com'+link\n",
    "    # fetch the content from url\n",
    "    page_response = requests.get(page_link, timeout=5)\n",
    "    # parse html\n",
    "    page_content = BeautifulSoup(page_response.content, \"html.parser\")\n",
    "    return page_content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "#coleta nomes e links para cada país/continente\n",
    "page_content = get_page()\n",
    "countries = []\n",
    "div = page_content.find(\"ul\", {\"id\": \"countries-select\"})\n",
    "for a in div.findAll('a',href=True):\n",
    "    countries.append([a.text, a['href']])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 4min 40s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "#coleta nomes e links de copetições a partir de 2005\n",
    "leagues = pd.DataFrame(columns=['Country','Tournament','Season','Link'])\n",
    "for country in countries:\n",
    "    page_content = get_page(country[1]) \n",
    "    table = page_content.find_all('table')[0]\n",
    "    for tbody in table.find_all('tbody'):\n",
    "        for row in tbody.find_all(['th','td']):\n",
    "            if row.name == 'th':\n",
    "                temporada = row.text\n",
    "                if int(temporada.split('/')[0]) < 2005:\n",
    "                    break\n",
    "            else:\n",
    "                leagues.loc[len(leagues)] = [country[0],row.text,temporada,row.select('a')[0].attrs['href']]\n",
    "\n",
    "leagues = leagues[~((leagues['Country'] != 'World') & (leagues['Tournament'] == 'World Cup'))]\n",
    "leagues.to_excel('data/Tournament Links.xlsx', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 4min 27s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "leagues = pd.DataFrame(columns=['Country','Tournament','Season','Link'])\n",
    "for country in countries:\n",
    "    page_link = 'http://www.betexplorer.com'+country[1]\n",
    "    # fetch the content from url\n",
    "    page_response = requests.get(page_link, timeout=5)\n",
    "    # parse html\n",
    "    page_content = BeautifulSoup(page_response.content, \"html.parser\")    \n",
    "    table = page_content.find_all('table')[0]\n",
    "    for tbody in table.find_all('tbody'):\n",
    "        for row in tbody.find_all(['th','td']):\n",
    "            if row.name == 'th':\n",
    "                temporada = row.text\n",
    "                if int(temporada.split('/')[0]) < 2005:\n",
    "                    break\n",
    "            else:\n",
    "                leagues.loc[len(leagues)] = [country[0],row.text,temporada,row.select('a')[0].attrs['href']]\n",
    "\n",
    "leagues = leagues[~((leagues['Country'] != 'World') & (leagues['Tournament'] == 'World Cup'))]\n",
    "leagues.to_excel('data/Tournament Links.xlsx', index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

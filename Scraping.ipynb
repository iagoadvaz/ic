{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from bs4 import BeautifulSoup\n",
    "import requests\n",
    "import pandas as pd\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 269,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_page(link = '/soccer'):\n",
    "    page_link = 'http://www.betexplorer.com'+link    \n",
    "    try:\n",
    "        # fetch the content from url\n",
    "        page_response = requests.get(page_link, timeout=5)\n",
    "        # parse html\n",
    "        page_content = BeautifulSoup(page_response.content, \"html.parser\")\n",
    "    except:\n",
    "        #caso a página não responda, espera por 3min e tenta novamente\n",
    "        time.sleep(180)\n",
    "        page_response = requests.get(page_link, timeout=5)\n",
    "        # parse html\n",
    "        page_content = BeautifulSoup(page_response.content, \"html.parser\")\n",
    "    return page_content\n",
    "\n",
    "\n",
    "def scrapGroupPhase(page, page_link,country, tournament, season):\n",
    "    #df_goals = pd.DataFrame(columns=['Match_Id','Team_Id', 'Time','Player_Name']) #para coleta d\n",
    "    df = pd.DataFrame(columns=['Country','Tournament', 'Season','Round','Home', 'Away','Score','Bet_Home','Bet_Drawn','Bet_Away','Game_Date','Game_Details','Fase'])\n",
    "    #div = page_content.find_all('ul', attrs = {'class' : 'list-tabs list-tabs--secondary'})\n",
    "    th_position = 0\n",
    "    td_position = 0\n",
    "    data = []\n",
    "    for content in page:\n",
    "        for li in content.find_all('li'):            \n",
    "            fase = li.text\n",
    "            rodada =''\n",
    "            try: \n",
    "                link = li.select('a')[0].attrs['href']\n",
    "                page_content = get_page(page_link+link)\n",
    "            except:\n",
    "                page_content = get_page(page_link)\n",
    "            \n",
    "            try:\n",
    "                table = page_content.find_all('table')[0]\n",
    "                for row in table.find_all(['td', 'th']):\n",
    "                    if row.name == 'th' and th_position == 0:\n",
    "                        rodada = row.text\n",
    "                        data = [country, tournament, season, rodada]\n",
    "                        th_position = 1\n",
    "                    elif row.name == 'td':\n",
    "                        if th_position == 0:\n",
    "                            if rodada == '':\n",
    "                                rodada = fase\n",
    "                            data = [country, tournament, season, rodada]\n",
    "                            th_position = 1\n",
    "                        if td_position == 0:\n",
    "                            data.append(row.text.split(' - ')[0])\n",
    "                            data.append(row.text.split(' - ')[1])\n",
    "                            for a in row.find_all('a', href=True):\n",
    "                                link = a['href']\n",
    "                                #df_goals = scrapGoals(len(df),[row.text.split(' - ')[0],row.text.split(' - ')[1]],link, df_goals)\n",
    "                        elif 2 <= td_position <= 4:\n",
    "                            try:\n",
    "                                data.append(row.select('span')[2].attrs['data-odd'])\n",
    "                            except:\n",
    "                                try: \n",
    "                                    data.append(row.attrs['data-odd'])\n",
    "                                except:\n",
    "                                    data.append(row.text)                    \n",
    "                        else:\n",
    "                            data.append(row.text)\n",
    "                        td_position+=1       \n",
    "                        if td_position == 6:\n",
    "                            data.append(link)\n",
    "                            data.append(fase)\n",
    "                            df.loc[len(df)] = data\n",
    "                            data = [country, tournament, season, rodada]\n",
    "                            th_position = 0\n",
    "                            td_position = 0\n",
    "            except:\n",
    "                continue\n",
    "    #return df, df_goals\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 268,
   "metadata": {},
   "outputs": [],
   "source": [
    "def scrapChampionship(page_content, country, tournament, season):\n",
    "    #df_goals = pd.DataFrame(columns=['Match_Id','Team_Id', 'Time','Player_Name'])\n",
    "    df = pd.DataFrame(columns=['Country','Tournament', 'Season','Round','Home', 'Away','Score','Bet_Home','Bet_Drawn','Bet_Away','Game_Date','Game_Details','Fase'])\n",
    "    th_position = 0\n",
    "    td_position = 0\n",
    "    rodada = ''\n",
    "    data = [country,tournament, season, rodada]\n",
    "    try:\n",
    "        table = page_content.find_all('table')[0]\n",
    "    except:\n",
    "        div = page_content.find_all('div', attrs = {'class' : 'nodata'})[0]\n",
    "        return div.text\n",
    "    for row in table.find_all(['td', 'th']):\n",
    "        if row.name == 'th' and th_position == 0:\n",
    "            rodada = row.text\n",
    "            data = [country, tournament, season, rodada]\n",
    "            th_position = 1\n",
    "        elif row.name == 'td':\n",
    "            if td_position == 0:\n",
    "                data.append(row.text.split(' - ')[0])\n",
    "                data.append(row.text.split(' - ')[1])\n",
    "                for a in row.find_all('a', href=True):\n",
    "                    link = a['href']\n",
    "                    #df_goals = scrapGoals(len(df),[row.text.split(' - ')[0],row.text.split(' - ')[1]],link, df_goals)\n",
    "            elif 2 <= td_position <= 4:\n",
    "                try:\n",
    "                    data.append(row.select('span')[2].attrs['data-odd'])\n",
    "                except:\n",
    "                    try: \n",
    "                        data.append(row.attrs['data-odd'])\n",
    "                    except:\n",
    "                        data.append(row.text)                    \n",
    "            else:\n",
    "                data.append(row.text)\n",
    "            td_position+=1       \n",
    "            if td_position == 6:\n",
    "                data.append(link)\n",
    "                data.append('')\n",
    "                df.loc[len(df)] = data\n",
    "                data = [country, tournament, season, rodada]\n",
    "                th_position = 0\n",
    "                td_position = 0\n",
    "    #return df, df_goals\n",
    "    return df\n",
    "\n",
    "def scrapGoals(match_id, team_id, page_link, df_goals):\n",
    "    page_content = get_page(page_link)\n",
    "    for ul in page_content.find_all('ul', attrs = {'class' : 'list-details list-details--shooters'}):\n",
    "        i = 0\n",
    "        for li in ul.findAll('li'):\n",
    "            if len(li) > 1:\n",
    "                for tr in li.findAll('tr'):\n",
    "                    #home team\n",
    "                    if i == 0:\n",
    "                        df_goals.loc[len(df_goals)] = [match_id, team_id[0], tr.text.split('.')[0],tr.text.split('.')[1]]\n",
    "                    #away team\n",
    "                    else:\n",
    "                        df_goals.loc[len(df_goals)] = [match_id, team_id[1], tr.text.split('.')[0],tr.text.split('.')[1]]\n",
    "            i = 1\n",
    "\n",
    "    return df_goals"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 290,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df_tournaments_links = pd.read_csv('Tournament Links.csv')\n",
    "log_columns = list(df_tournaments_links.columns)\n",
    "log_columns.append('Function')\n",
    "log_columns.append('Error')\n",
    "log = pd.DataFrame(columns= log_columns)\n",
    "df_tournaments_links.Link = df_tournaments_links.Link+'results/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 283,
   "metadata": {},
   "outputs": [],
   "source": [
    "current_country = df_tournaments_links.loc[df_tournaments_links.index.min()].Country\n",
    "df_country_competitions = pd.DataFrame(columns=['Country','Tournament', 'Season','Round','Home', 'Away','Score','Bet_Home','Bet_Drawn','Bet_Away','Game_Date','Game_Details','Fase'])\n",
    "for row in df_tournaments_links.values:\n",
    "    row = list(row)\n",
    "    page_link = row[3]\n",
    "    try:\n",
    "        page_content = get_page(page_link)\n",
    "    except:\n",
    "        row.append('get_page')\n",
    "        row.append('Timeout')\n",
    "        log.loc[len(log)] = row\n",
    "        continue\n",
    "        \n",
    "    div = page_content.find_all('ul', attrs = {'class' : 'list-tabs list-tabs--secondary'})\n",
    "    try:\n",
    "        if len(div) > 0:\n",
    "            row.append('scrapGroupPhase')\n",
    "            df = scrapGroupPhase(div, page_link,row[0], row[1], row[2])\n",
    "            #df, df_goals = scrapGroupPhase(div, page_link)\n",
    "        else:\n",
    "            row.append('scrapChampionship')\n",
    "            #df, df_goals = scrapChampionship(page_content)\n",
    "            df = scrapChampionship(page_content,row[0], row[1], row[2])\n",
    "        #if len(df_goals) > 0:\n",
    "            #df_goals.to_excel('data/'+row[1]+' - '+row[2].split('/')[0]+' - Goals.xlsx', index=False)\n",
    "        df_country_competitions = df_country_competitions.append(df)\n",
    "        #if row[0] == current_country:\n",
    "        #    df_country_competitions = df_country_competitions.append(df)\n",
    "        #else:\n",
    "        #    df_country_competitions.drop_duplicates(['Country','Tournament','Season','Home','Away','Score','Bet_Home',\n",
    "        #                                             'Bet_Drawn','Bet_Away','Game_Date','Game_Details'],inplace=True)\n",
    "        #    df_country_competitions.to_excel('data/a'+current_country+'.xlsx', index=False)\n",
    "        #    #df_country_competitions.to_excel('data/teste.xlsx', index=False)\n",
    "        #    df_country_competitions = df\n",
    "        #    current_country = row[0]\n",
    "    except Exception as e:\n",
    "        if df == 'No matches found':\n",
    "            row.append(df)\n",
    "        else:\n",
    "            row.append(str(e))\n",
    "        log.loc[len(log)] = row\n",
    "        print(row)\n",
    "df_country_competitions.drop_duplicates(['Country','Tournament','Season','Home','Away','Score','Bet_Home',\n",
    "                                         'Bet_Drawn','Bet_Away','Game_Date','Game_Details'],inplace=True)\n",
    "df_country_competitions.to_csv('Games_Results.csv',encoding='latin1',index_label='GameID')\n",
    "log.to_csv('alog.csv', encoding='latin1', index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

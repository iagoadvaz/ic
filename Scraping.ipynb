{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from bs4 import BeautifulSoup\n",
    "import requests\n",
    "import pandas as pd\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_page(link = '/soccer'):\n",
    "    page_link = 'http://www.betexplorer.com'+link    \n",
    "    try:\n",
    "        # fetch the content from url\n",
    "        page_response = requests.get(page_link, timeout=5)\n",
    "        # parse html\n",
    "        page_content = BeautifulSoup(page_response.content, \"html.parser\")\n",
    "    except:\n",
    "        #caso a página não responda, espera por 5min e tenta novamente\n",
    "        time.sleep(300)\n",
    "        page_response = requests.get(page_link, timeout=60)\n",
    "        # parse html\n",
    "        page_content = BeautifulSoup(page_response.content, \"html.parser\")\n",
    "    return page_content\n",
    "\n",
    "\n",
    "def scrapGroupPhase(page, page_link, tournament, season):\n",
    "    #df_goals = pd.DataFrame(columns=['Match_Id','Team_Id', 'Time','Player_Name']) #para coleta d\n",
    "    df = pd.DataFrame(columns=['Tournament', 'Season','Round','Home', 'Away','Score','Bet_Home','Bet_Drawn','Bet_Away','Game_Date','Game_Details','Fase'])\n",
    "    #div = page_content.find_all('ul', attrs = {'class' : 'list-tabs list-tabs--secondary'})\n",
    "    th_position = 0\n",
    "    td_position = 0\n",
    "    data = []\n",
    "    for content in page:\n",
    "        for li in content.find_all('li'):            \n",
    "            fase = li.text\n",
    "            link = li.select('a')[0].attrs['href']\n",
    "            page_content = get_page(page_link+link)\n",
    "            table = page_content.find_all('table')[0]\n",
    "            for row in table.find_all(['td', 'th']):\n",
    "                if row.name == 'th' and th_position == 0:\n",
    "                    rodada = row.text\n",
    "                    data = [tournament, season, rodada]\n",
    "                    th_position = 1\n",
    "                elif row.name == 'td':\n",
    "                    if th_position == 0:\n",
    "                        rodada = fase\n",
    "                        data = [tournament, season, rodada]\n",
    "                        th_position = 1\n",
    "                    if td_position == 0:\n",
    "                        data.append(row.text.split(' - ')[0])\n",
    "                        data.append(row.text.split(' - ')[1])\n",
    "                        for a in row.find_all('a', href=True):\n",
    "                            link = a['href']\n",
    "                            #df_goals = scrapGoals(len(df),[row.text.split(' - ')[0],row.text.split(' - ')[1]],link, df_goals)\n",
    "                    elif 2 <= td_position <= 4:\n",
    "                        try:\n",
    "                            data.append(row.select('span')[2].attrs['data-odd'])\n",
    "                        except:\n",
    "                            try: \n",
    "                                data.append(row.attrs['data-odd'])\n",
    "                            except:\n",
    "                                data.append(row.text)                    \n",
    "                    else:\n",
    "                        data.append(row.text)\n",
    "                    td_position+=1       \n",
    "                    if td_position == 6:\n",
    "                        data.append(link)\n",
    "                        data.append(fase)\n",
    "                        df.loc[len(df)] = data\n",
    "                        data = [tournament, season, rodada]\n",
    "                        th_position = 0\n",
    "                        td_position = 0\n",
    "    #return df, df_goals\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def scrapChampionship(page_content, tournament, season):\n",
    "    #df_goals = pd.DataFrame(columns=['Match_Id','Team_Id', 'Time','Player_Name'])\n",
    "    df = pd.DataFrame(columns=['Tournament', 'Season','Round','Home', 'Away','Score','Bet_Home','Bet_Drawn','Bet_Away','Game_Date','Game_Details','Fase'])\n",
    "    th_position = 0\n",
    "    td_position = 0\n",
    "    data = []\n",
    "    table = page_content.find_all('table')[0]\n",
    "    for row in table.find_all(['td', 'th']):\n",
    "        if row.name == 'th' and th_position == 0:\n",
    "            rodada = row.text\n",
    "            data = [tournament, season, rodada]\n",
    "            th_position = 1\n",
    "        elif row.name == 'td':\n",
    "            if td_position == 0:\n",
    "                data.append(row.text.split(' - ')[0])\n",
    "                data.append(row.text.split(' - ')[1])\n",
    "                for a in row.find_all('a', href=True):\n",
    "                    link = a['href']\n",
    "                    #df_goals = scrapGoals(len(df),[row.text.split(' - ')[0],row.text.split(' - ')[1]],link, df_goals)\n",
    "            elif 2 <= td_position <= 4:\n",
    "                try:\n",
    "                    data.append(row.select('span')[2].attrs['data-odd'])\n",
    "                except:\n",
    "                    try: \n",
    "                        data.append(row.attrs['data-odd'])\n",
    "                    except:\n",
    "                        data.append(row.text)                    \n",
    "            else:\n",
    "                data.append(row.text)\n",
    "            td_position+=1       \n",
    "            if td_position == 6:\n",
    "                data.append(link)\n",
    "                data.append('')\n",
    "                df.loc[len(df)] = data\n",
    "                data = [tournament, season, rodada]\n",
    "                th_position = 0\n",
    "                td_position = 0\n",
    "    #return df, df_goals\n",
    "    return df\n",
    "\n",
    "def scrapGoals(match_id, team_id, page_link, df_goals):\n",
    "    page_content = get_page(page_link)\n",
    "    for ul in page_content.find_all('ul', attrs = {'class' : 'list-details list-details--shooters'}):\n",
    "        i = 0\n",
    "        for li in ul.findAll('li'):\n",
    "            if len(li) > 1:\n",
    "                for tr in li.findAll('tr'):\n",
    "                    #home team\n",
    "                    if i == 0:\n",
    "                        df_goals.loc[len(df_goals)] = [match_id, team_id[0], tr.text.split('.')[0],tr.text.split('.')[1]]\n",
    "                    #away team\n",
    "                    else:\n",
    "                        df_goals.loc[len(df_goals)] = [match_id, team_id[1], tr.text.split('.')[0],tr.text.split('.')[1]]\n",
    "            i = 1\n",
    "\n",
    "    return df_goals"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_tournaments_links = pd.read_excel('data/Tournament Links.xlsx')\n",
    "log_columns = list(df_tournaments_links.columns)\n",
    "log_columns.append('Function')\n",
    "log_columns.append('Error')\n",
    "log = pd.DataFrame(columns= log_columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#seleciona torneios a serem coletados\n",
    "df_tournaments_links = df_tournaments_links[(df_tournaments_links.Country >= 'Sweden')]\n",
    "df_tournaments_links"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "current_country = df_tournaments_links.loc[df_tournaments_links.index.min()].Country\n",
    "df_country_competitions = pd.DataFrame(columns=['Tournament', 'Season','Round','Home', 'Away','Score','Bet_Home','Bet_Drawn','Bet_Away','Game_Date','Game_Details','Fase'])\n",
    "for row in df_tournaments_links.values:\n",
    "    row = list(row)\n",
    "    page_link = row[3]\n",
    "    try:\n",
    "        page_content = get_page(page_link+'results')\n",
    "    except:\n",
    "        row.append('get_page')\n",
    "        row.append('Timeout')\n",
    "        log.loc[len(log)] = row\n",
    "        break\n",
    "    div = page_content.find_all('ul', attrs = {'class' : 'list-tabs list-tabs--secondary'})\n",
    "    try:\n",
    "        if len(div) > 0:\n",
    "            row.append('scrapGroupPhase')\n",
    "            df = scrapGroupPhase(div, page_link, row[1], row[2])\n",
    "            #df, df_goals = scrapGroupPhase(div, page_link)\n",
    "        else:\n",
    "            row.append('scrapChampionship')\n",
    "            #df, df_goals = scrapChampionship(page_content)\n",
    "            df = scrapChampionship(page_content, row[1], row[2])        \n",
    "        #if len(df_goals) > 0:\n",
    "            #df_goals.to_excel('data/'+row[1]+' - '+row[2].split('/')[0]+' - Goals.xlsx', index=False)\n",
    "        if row[0] == current_country:\n",
    "            df_country_competitions = df_country_competitions.append(df)\n",
    "        else:\n",
    "            df_country_competitions.to_excel('data/'+current_country+'.xlsx', index=False)\n",
    "            df_country_competitions = df\n",
    "            current_country = row[0]\n",
    "    except Exception as e:\n",
    "        row.append(str(e))\n",
    "        log.loc[len(log)] = row\n",
    "        print(row)\n",
    "df_country_competitions.to_excel('data/'+current_country+'.xlsx', index=False)\n",
    "log.to_csv('data/log.csv', encoding=None, index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "#célula de testes\n",
    "'''page_link = '/soccer/andorra/primera-divisio/results'\n",
    "page_content = get_page(page_link)\n",
    "print('Page')\n",
    "div = page_content.find_all('ul', attrs = {'class' : 'list-tabs list-tabs--secondary'})\n",
    "if len(div) > 0:\n",
    "    print('Group')\n",
    "    #df, df_goals = scrapGroupPhase(div, page_link)\n",
    "    df = scrapGroupPhase(div, page_link, 'Primeira Liga', '2017')\n",
    "else:\n",
    "    print('Champ')\n",
    "    #df, df_goals = scrapChampionship(page_content)\n",
    "    df = scrapChampionship(page_content, 'Primeira Liga', '2017')'''"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
